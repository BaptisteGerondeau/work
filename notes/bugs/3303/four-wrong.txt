## ZSPAGE

crash> kmem -s zspage

    CACHE    NAME                 OBJSIZE  ALLOCATED     TOTAL  SLABS  SSIZE
    eb9c6200 zspage                    28          1       128      1     4k

----

crash> kmem -S zspage

    CACHE    NAME                 OBJSIZE  ALLOCATED     TOTAL  SLABS  SSIZE
    eb9c6200 zspage                    28          1       128      1     4k
    CPU 0 KMEM_CACHE_CPU:
      ff7c0d30
    CPU 0 SLAB:
      (empty)
    CPU 0 PARTIAL:
      (empty)
    CPU 1 KMEM_CACHE_CPU:
      ff7d2d30
    CPU 1 SLAB:
      (empty)
    CPU 1 PARTIAL:
      (empty)
    CPU 2 KMEM_CACHE_CPU:
      ff7e4d30
    CPU 2 SLAB:
      (empty)
    CPU 2 PARTIAL:
      (empty)
    CPU 3 KMEM_CACHE_CPU:
      ff7f6d30
    CPU 3 SLAB:
      (empty)
    CPU 3 PARTIAL:
      (empty)
    KMEM_CACHE_NODE   NODE  SLABS  PARTIAL  PER-CPU
    eb93bec0             0      1        1        0
    NODE 0 PARTIAL:
      SLAB      MEMORY    NODE  TOTAL  ALLOCATED  FREE
      ee1daef8  e9d4e000     0    128          1   127
    NODE 0 FULL:
      (not tracked)

----

1st (and only) slab object is the first zspage: 

    crash> struct zspage e9d4e000
    struct zspage {
      {
        fullness = 0x3,
        class = 0xda,
        isolated = 0x5,
        magic = 0xad
      },
      inuse = 0x6b6b6b6b, 				-> POISON
      freeobj = 0x6b6b6b6b,				-> POISON
      first_page = 0x6b6b6b6b,		-> POISON
      list = {
        next = 0x6b6b6b6b,				-> POISON
        prev = 0x6b6b6b6b				  -> POISON
      },
      lock = {
        raw_lock = {
          lock = 0xa56b6b6b				-> ???
        }
      }
    }

and this is weird. why would zspage be still poisoned (result from kmem_cache_alloc) if :

    static struct zspage *alloc_zspage(struct zs_pool *pool,
              struct size_class *class,
              gfp_t gfp)
    {
      int i;
      struct page *pages[ZS_MAX_PAGES_PER_ZSPAGE];
      struct zspage *zspage = cache_alloc_zspage(pool, gfp);

      if (!zspage)
        return NULL;

      memset(zspage, 0, sizeof(struct zspage)); -> this would have zeroed all zspage
      zspage->magic = ZSPAGE_MAGIC;             -> this would have put 0x58 into zspage->magic
      migrate_lock_init(zspage);

looks like zspage wasn't initialized (or initialized correctly). 

by instrumenting the execution path I saw that the code responsible to memset(0) zspage ran:

    root@zramarmhf:~$ mkfs.ext4 /dev/zram0
    mke2fs 1.44.2 (14-May-2018)
    Discarding device blocks: done
    Creating filesystem with 262144 4k blocks and 65536 inodes
    Filesystem UUID: d084f7d3-06a7-456d-9cb4-662333c213dd
    Superblock backups stored on blocks:
      32768, 98304, 163840, 229376

    Allocating group tables: done
    Writing inode tables: done
    Creating journal (8192 blocks): done
    Writing superblocks and filesystem accounting information: 

    [  292.156933] AFTER CACHE_ALLOC_ZSPAGE
    [  292.157229] ZSPAGE IS NOT NULL
    [  292.157775] AFTER MIGRATE LOCK INIT
    [  292.158427] AFTER CREATE_PAGE_CHAIN
    [  292.158963] AFTER INIT ZSPAGE

[  292.160401] Unable to handle kernel NULL pointer dereference at virtual address 00000000

which means that memset() didn't went through all zspage (since it had the poision values).

after this i made some changes to struct zspage to check if bit fields were problematic for arm32 (thought that maybe either compiler could be doing something wrong, based on specs, or available registers for returning struct zspage were not enough, things like that). removing bit fields just expanded, obviously, size of struct szpage and it was, still, poisoned (at least it served to show me that bigger unsigned ints were also poisoned).

even with the changes I got:

root@zramarmhf:~$ modprobe zram
[  140.855549] CREATE_CACHE: radix_tree_node(375:session-3.scope)
[  140.855920] AFTER INIT MEMCG: radix_tree_node(375:session-3.scope)
[  140.856306] AFTER KMEM CACHE CREATE: radix_tree_node(375:session-3.scope)
[  140.856698] AFTER LIST ADD: radix_tree_node(375:session-3.scope)
[  141.228894] zram: Added device: zram0
[  141.369377] CREATE_CACHE: bdev_cache(185:systemd-udevd.service)
[  141.369809] AFTER INIT MEMCG: bdev_cache(185:systemd-udevd.service)
[  141.370846] AFTER KMEM CACHE CREATE: bdev_cache(185:systemd-udevd.service)
[  141.371372] AFTER LIST ADD: bdev_cache(185:systemd-udevd.service)

root@zramarmhf:~$ echo 1073741824 > /sys/devices/virtual/block/zram0/disksize
[  157.028636] CREATE_CACHE: zs_handle
[  157.029051] AFTER INIT MEMCG: zs_handle
[  157.032059] AFTER KMEM CACHE CREATE: zs_handle
[  157.032622] AFTER LIST ADD: zs_handle
[  157.033181] CREATE_CACHE: zspage
[  157.033539] AFTER INIT MEMCG: zspage
[  157.034843] AFTER KMEM CACHE CREATE: zspage
[  157.035265] AFTER LIST ADD: zspage
[  157.035756] ZSPAGE CREATED ?
[  157.036329] RETURNING 0
[  157.040385] zram0: detected capacity change from 0 to 1073741824

root@zramarmhf:~$ mkfs.ext4 /dev/zram0
mke2fs 1.44.2 (14-May-2018)
Discarding device blocks: done
Creating filesystem with 262144 4k blocks and 65536 inodes
Filesystem UUID: baa1c722-d9dc-4ce2-94e0-73ed010ec1a2
Superblock backups stored on blocks:
  32768, 98304, 163840, 229376

Allocating group tables: done
Writing inode tables: done
Creating journal (8192 blocks): done
Writing superblocks and filesystem accounting information: 
[  179.620377] AFTER CACHE_ALLOC_ZSPAGE
[  179.620740] ZSPAGE IS NOT NULL
[  179.620936] AFTER MIGRATE LOCK INIT
[  179.621390] AFTER CREATE_PAGE_CHAIN
[  179.621755] AFTER INIT ZSPAGE
[  179.622888] Unable to handle kernel NULL pointer dereference at virtual address 0000000c
[  179.623833] pgd = (ptrval)
[  179.624119] [0000000c] *pgd=6b959003, *pmd=00000000
[  179.625411] Internal error: Oops: 206 [#1] SMP ARM
[  179.626194] Modules linked in: zram zsmalloc evdev ip_tables x_tables autofs4

and i also checked slub_debug to see if slub was being corrupted somehow:

root@zramarmhf:~$ dd if=/dev/urandom of=/dev/zram0 bs=1M count=1
[  104.302157] TRACE zspage alloc 0x(ptrval) inuse=19 fp=0x  (null)
[  104.303175] CPU: 0 PID: 525 Comm: dd Not tainted 4.17.0+ #14
[  104.303622] Hardware name: Generic DT based system
[  104.305044] [<c043bb50>] (unwind_backtrace) from [<c0434e10>] (show_stack+0x20/0x24)
[  104.305670] [<c0434e10>] (show_stack) from [<c0ca6858>] (dump_stack+0x94/0xa8)
[  104.306199] [<c0ca6858>] (dump_stack) from [<c063c47c>] (alloc_debug_processing+0x90/0x1a0)
[  104.306797] [<c063c47c>] (alloc_debug_processing) from [<c063caa8>] (___slab_alloc.constprop.14+0x51c/0x570)
[  104.307465] [<c063caa8>] (___slab_alloc.constprop.14) from [<c063d3bc>] (kmem_cache_alloc+0x178/0x250)
[  104.308582] [<c063d3bc>] (kmem_cache_alloc) from [<bf035184>] (zs_malloc+0xd4/0x42c [zsmalloc])
[  104.309231] [<bf035184>] (zs_malloc [zsmalloc]) from [<bf040670>] (zram_bvec_rw.constprop.2+0x420/0x724 [zram])
[  104.309948] [<bf040670>] (zram_bvec_rw.constprop.2 [zram]) from [<bf040b00>] (zram_make_request+0x18c/0x3a4 [zram])
[  104.310680] [<bf040b00>] (zram_make_request [zram]) from [<c0801094>] (generic_make_request+0x188/0x378)
[  104.311340] [<c0801094>] (generic_make_request) from [<c08012e4>] (submit_bio+0x60/0x1a4)
[  104.311988] [<c08012e4>] (submit_bio) from [<c069f28c>] (submit_bh_wbc+0x190/0x1c0)
[  104.312878] [<c069f28c>] (submit_bh_wbc) from [<c069f534>] (__block_write_full_page+0x278/0x4ec)
[  104.313880] [<c069f534>] (__block_write_full_page) from [<c069f9a4>] (block_write_full_page+0xf4/0x104)
[  104.314532] [<c069f9a4>] (block_write_full_page) from [<c06a3204>] (blkdev_writepage+0x24/0x28)
[  104.315145] [<c06a3204>] (blkdev_writepage) from [<c05d8924>] (__writepage+0x24/0x5c)
[  104.315718] [<c05d8924>] (__writepage) from [<c05d9384>] (write_cache_pages+0x1f4/0x508)
[  104.316277] [<c05d9384>] (write_cache_pages) from [<c05da000>] (generic_writepages+0x64/0x90)
[  104.316874] [<c05da000>] (generic_writepages) from [<c06a31b4>] (blkdev_writepages+0x18/0x1c)
[  104.317493] [<c06a31b4>] (blkdev_writepages) from [<c05dbcc0>] (do_writepages+0x54/0xf0)
[  104.318066] [<c05dbcc0>] (do_writepages) from [<c05ca890>] (__filemap_fdatawrite_range+0xe4/0x11c)
[  104.318700] [<c05ca890>] (__filemap_fdatawrite_range) from [<c05ca990>] (filemap_write_and_wait+0x48/0x9c)
[  104.319386] [<c05ca990>] (filemap_write_and_wait) from [<c06a3e28>] (sync_blockdev.part.2+0x20/0x24)
[  104.320102] [<c06a3e28>] (sync_blockdev.part.2) from [<c06a406c>] (__blkdev_put+0x84/0x254)
[  104.321082] [<c06a406c>] (__blkdev_put) from [<c06a4290>] (blkdev_put+0x54/0x154)
[  104.321638] [<c06a4290>] (blkdev_put) from [<c06a43b8>] (blkdev_close+0x28/0x30)
[  104.322164] [<c06a43b8>] (blkdev_close) from [<c0661884>] (__fput+0x98/0x1ec)
[  104.322670] [<c0661884>] (__fput) from [<c0661a48>] (____fput+0x18/0x1c)
[  104.323157] [<c0661a48>] (____fput) from [<c0499a88>] (task_work_run+0xb4/0xd8)
[  104.323694] [<c0499a88>] (task_work_run) from [<c04343d4>] (do_work_pending+0xf4/0xf8)
[  104.324265] [<c04343d4>] (do_work_pending) from [<c0401184>] (slow_work_pending+0xc/0x20)
[  104.324889] Exception stack(0xebbc9fb0 to 0xebbc9ff8)
[  104.325375] 9fa0:                                     00000000 00000001 0000006c 00000000
[  104.325986] 9fc0: 0043b258 0043b258 00000001 00000006 00000001 00000000 00000001 b6f6cdd0
[  104.326567] 9fe0: 00000006 bec8a718 b6edb363 b6e65206 20070030 00000001
[  104.328768] Unable to handle kernel NULL pointer dereference at virtual address 00000000
...
[  104.378242] 9fa0: 00000000 ebbc9fb0 c0401184 c04342ec 00000000 00000001 0000006c 00000000
[  104.379134] 9fc0: 0043b258 0043b258 00000001 00000006 00000001 00000000 00000001 b6f6cdd0
[  104.380092] 9fe0: 00000006 bec8a718 b6edb363 b6e65206 20070030 00000001 00000000 00000000
[  104.381142] [<bf034e34>] (zs_map_object [zsmalloc]) from [<bf040510>] (zram_bvec_rw.constprop.2+0x2c0/0x724 [zram])
[  104.382316] [<bf040510>] (zram_bvec_rw.constprop.2 [zram]) from [<bf040b00>] (zram_make_request+0x18c/0x3a4 [zram])
[  104.383477] [<bf040b00>] (zram_make_request [zram]) from [<c0801094>] (generic_make_request+0x188/0x378)
[  104.384600] [<c0801094>] (generic_make_request) from [<c08012e4>] (submit_bio+0x60/0x1a4)
[  104.385474] [<c08012e4>] (submit_bio) from [<c069f28c>] (submit_bh_wbc+0x190/0x1c0)
[  104.386183] [<c069f28c>] (submit_bh_wbc) from [<c069f534>] (__block_write_full_page+0x278/0x4ec)
[  104.387033] [<c069f534>] (__block_write_full_page) from [<c069f9a4>] (block_write_full_page+0xf4/0x104)
[  104.388040] [<c069f9a4>] (block_write_full_page) from [<c06a3204>] (blkdev_writepage+0x24/0x28)
[  104.388897] [<c06a3204>] (blkdev_writepage) from [<c05d8924>] (__writepage+0x24/0x5c)
[  104.389616] [<c05d8924>] (__writepage) from [<c05d9384>] (write_cache_pages+0x1f4/0x508)
[  104.390316] [<c05d9384>] (write_cache_pages) from [<c05da000>] (generic_writepages+0x64/0x90)
[  104.391085] [<c05da000>] (generic_writepages) from [<c06a31b4>] (blkdev_writepages+0x18/0x1c)
[  104.391830] [<c06a31b4>] (blkdev_writepages) from [<c05dbcc0>] (do_writepages+0x54/0xf0)
[  104.392820] [<c05dbcc0>] (do_writepages) from [<c05ca890>] (__filemap_fdatawrite_range+0xe4/0x11c)
[  104.393868] [<c05ca890>] (__filemap_fdatawrite_range) from [<c05ca990>] (filemap_write_and_wait+0x48/0x9c)
[  104.394794] [<c05ca990>] (filemap_write_and_wait) from [<c06a3e28>] (sync_blockdev.part.2+0x20/0x24)
[  104.395604] [<c06a3e28>] (sync_blockdev.part.2) from [<c06a406c>] (__blkdev_put+0x84/0x254)
[  104.396525] [<c06a406c>] (__blkdev_put) from [<c06a4290>] (blkdev_put+0x54/0x154)
[  104.397291] [<c06a4290>] (blkdev_put) from [<c06a43b8>] (blkdev_close+0x28/0x30)
[  104.397961] [<c06a43b8>] (blkdev_close) from [<c0661884>] (__fput+0x98/0x1ec)
[  104.398623] [<c0661884>] (__fput) from [<c0661a48>] (____fput+0x18/0x1c)
[  104.399198] [<c0661a48>] (____fput) from [<c0499a88>] (task_work_run+0xb4/0xd8)
[  104.399945] [<c0499a88>] (task_work_run) from [<c04343d4>] (do_work_pending+0xf4/0xf8)
[  104.400818] [<c04343d4>] (do_work_pending) from [<c0401184>] (slow_work_pending+0xc/0x20)
[  104.401596] Exception stack(0xebbc9fb0 to 0xebbc9ff8)
[  104.402098] 9fa0:                                     00000000 00000001 0000006c 00000000
[  104.402839] 9fc0: 0043b258 0043b258 00000001 00000006 00000001 00000000 00000001 b6f6cdd0
[  104.403588] 9fe0: 00000006 bec8a718 b6edb363 b6e65206 20070030 00000001
[  104.404515] Code: e5928000 e006039c e0889006 e5995014 (e5953000)
[  104.405873] ---[ end trace ae90ba11d4cfb190 ]---

AND then from the page cache commit attempt (from kernel thread):

[  109.327971] TRACE zspage alloc 0x(ptrval) inuse=19 fp=0x  (null)
[  109.328967] CPU: 3 PID: 127 Comm: kworker/u8:2 Tainted: G      D           4.17.0+ #14
[  109.329483] Hardware name: Generic DT based system
[  109.330463] Workqueue: writeback wb_workfn (flush-253:0)
[  109.331107] [<c043bb50>] (unwind_backtrace) from [<c0434e10>] (show_stack+0x20/0x24)
[  109.331646] [<c0434e10>] (show_stack) from [<c0ca6858>] (dump_stack+0x94/0xa8)
[  109.332120] [<c0ca6858>] (dump_stack) from [<c063c47c>] (alloc_debug_processing+0x90/0x1a0)
[  109.332638] [<c063c47c>] (alloc_debug_processing) from [<c063caa8>] (___slab_alloc.constprop.14+0x51c/0x570)
[  109.333263] [<c063caa8>] (___slab_alloc.constprop.14) from [<c063d3bc>] (kmem_cache_alloc+0x178/0x250)
[  109.334287] [<c063d3bc>] (kmem_cache_alloc) from [<bf035184>] (zs_malloc+0xd4/0x42c [zsmalloc])
[  109.334860] [<bf035184>] (zs_malloc [zsmalloc]) from [<bf040670>] (zram_bvec_rw.constprop.2+0x420/0x724 [zram])
[  109.335478] [<bf040670>] (zram_bvec_rw.constprop.2 [zram]) from [<bf040b00>] (zram_make_request+0x18c/0x3a4 [zram])
[  109.336147] [<bf040b00>] (zram_make_request [zram]) from [<c0801094>] (generic_make_request+0x188/0x378)
[  109.336760] [<c0801094>] (generic_make_request) from [<c08012e4>] (submit_bio+0x60/0x1a4)
[  109.337266] [<c08012e4>] (submit_bio) from [<c069f28c>] (submit_bh_wbc+0x190/0x1c0)
[  109.337774] [<c069f28c>] (submit_bh_wbc) from [<c069f534>] (__block_write_full_page+0x278/0x4ec)
[  109.338325] [<c069f534>] (__block_write_full_page) from [<c069f9a4>] (block_write_full_page+0xf4/0x104)
[  109.338908] [<c069f9a4>] (block_write_full_page) from [<c06a3204>] (blkdev_writepage+0x24/0x28)
[  109.339416] [<c06a3204>] (blkdev_writepage) from [<c05d8924>] (__writepage+0x24/0x5c)
[  109.339934] [<c05d8924>] (__writepage) from [<c05d9384>] (write_cache_pages+0x1f4/0x508)
[  109.340409] [<c05d9384>] (write_cache_pages) from [<c05da000>] (generic_writepages+0x64/0x90)
[  109.340958] [<c05da000>] (generic_writepages) from [<c06a31b4>] (blkdev_writepages+0x18/0x1c)
[  109.341466] [<c06a31b4>] (blkdev_writepages) from [<c05dbcc0>] (do_writepages+0x54/0xf0)
[  109.341983] [<c05dbcc0>] (do_writepages) from [<c0693ee0>] (__writeback_single_inode+0x44/0x43c)
[  109.342552] [<c0693ee0>] (__writeback_single_inode) from [<c06947b8>] (writeback_sb_inodes+0x1fc/0x4f4)
[  109.343151] [<c06947b8>] (writeback_sb_inodes) from [<c0694b20>] (__writeback_inodes_wb+0x70/0xbc)
[  109.343714] [<c0694b20>] (__writeback_inodes_wb) from [<c0694e04>] (wb_writeback+0x298/0x37c)
[  109.344281] [<c0694e04>] (wb_writeback) from [<c069577c>] (wb_workfn+0x214/0x510)
[  109.344714] [<c069577c>] (wb_workfn) from [<c04951b4>] (process_one_work+0x1c0/0x4b0)
[  109.345232] [<c04951b4>] (process_one_work) from [<c0496190>] (worker_thread+0x5c/0x580)
[  109.345698] [<c0496190>] (worker_thread) from [<c049bb60>] (kthread+0x16c/0x174)
[  109.346150] [<c049bb60>] (kthread) from [<c04011f8>] (ret_from_fork+0x14/0x3c)
[  109.346670] Exception stack(0xc825ffb0 to 0xc825fff8)
[  109.347117] ffa0:                                     00000000 00000000 00000000 00000000
[  109.347681] ffc0: 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
[  109.348191] ffe0: 00000000 00000000 00000000 00000000 00000013 00000000
[  109.350341] Unable to handle kernel NULL pointer dereference at virtual address 00000000
[  109.351116] pgd = (ptrval)
[  109.351425] [00000000] *pgd=80000040204003, *pmd=00000000
[  109.352862] Internal error: Oops: 206 [#2] SMP ARM
...
[  109.395170] ff20: 00000088 c1404d00 c825ff74 c825ff38 c0496190 c0495000 c8014940 c0f8f56c
[  109.396132] ff40: c1502e1b ed010800 c0496134 ed3738c0 c8014940 00000000 c825e000 c8140700
[  109.396979] ff60: c0496134 ed44be84 c825ffac c825ff78 c049bb60 c0496140 ed3738dc ed3738dc
[  109.397706] ff80: 00000000 c8014940 c049b9f4 00000000 00000000 00000000 00000000 00000000
[  109.398497] ffa0: 00000000 c825ffb0 c04011f8 c049ba00 00000000 00000000 00000000 00000000
[  109.399214] ffc0: 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
[  109.399988] ffe0: 00000000 00000000 00000000 00000000 00000013 00000000 00000000 00000000
[  109.401118] [<bf034e34>] (zs_map_object [zsmalloc]) from [<bf040510>] (zram_bvec_rw.constprop.2+0x2c0/0x724 [zram])
[  109.402283] [<bf040510>] (zram_bvec_rw.constprop.2 [zram]) from [<bf040b00>] (zram_make_request+0x18c/0x3a4 [zram])
[  109.403391] [<bf040b00>] (zram_make_request [zram]) from [<c0801094>] (generic_make_request+0x188/0x378)
[  109.404390] [<c0801094>] (generic_make_request) from [<c08012e4>] (submit_bio+0x60/0x1a4)
[  109.405282] [<c08012e4>] (submit_bio) from [<c069f28c>] (submit_bh_wbc+0x190/0x1c0)
[  109.406120] [<c069f28c>] (submit_bh_wbc) from [<c069f534>] (__block_write_full_page+0x278/0x4ec)
[  109.406983] [<c069f534>] (__block_write_full_page) from [<c069f9a4>] (block_write_full_page+0xf4/0x104)
[  109.408148] [<c069f9a4>] (block_write_full_page) from [<c06a3204>] (blkdev_writepage+0x24/0x28)
[  109.409101] [<c06a3204>] (blkdev_writepage) from [<c05d8924>] (__writepage+0x24/0x5c)
[  109.409972] [<c05d8924>] (__writepage) from [<c05d9384>] (write_cache_pages+0x1f4/0x508)
[  109.410848] [<c05d9384>] (write_cache_pages) from [<c05da000>] (generic_writepages+0x64/0x90)
[  109.411772] [<c05da000>] (generic_writepages) from [<c06a31b4>] (blkdev_writepages+0x18/0x1c)
[  109.412656] [<c06a31b4>] (blkdev_writepages) from [<c05dbcc0>] (do_writepages+0x54/0xf0)
[  109.413370] [<c05dbcc0>] (do_writepages) from [<c0693ee0>] (__writeback_single_inode+0x44/0x43c)
[  109.414004] [<c0693ee0>] (__writeback_single_inode) from [<c06947b8>] (writeback_sb_inodes+0x1fc/0x4f4)
[  109.414646] [<c06947b8>] (writeback_sb_inodes) from [<c0694b20>] (__writeback_inodes_wb+0x70/0xbc)
[  109.415321] [<c0694b20>] (__writeback_inodes_wb) from [<c0694e04>] (wb_writeback+0x298/0x37c)
[  109.416019] [<c0694e04>] (wb_writeback) from [<c069577c>] (wb_workfn+0x214/0x510)
[  109.416928] [<c069577c>] (wb_workfn) from [<c04951b4>] (process_one_work+0x1c0/0x4b0)
[  109.417521] [<c04951b4>] (process_one_work) from [<c0496190>] (worker_thread+0x5c/0x580)
[  109.418068] [<c0496190>] (worker_thread) from [<c049bb60>] (kthread+0x16c/0x174)
[  109.418699] [<c049bb60>] (kthread) from [<c04011f8>] (ret_from_fork+0x14/0x3c)
[  109.419255] Exception stack(0xc825ffb0 to 0xc825fff8)
[  109.419620] ffa0:                                     00000000 00000000 00000000 00000000
[  109.420438] ffc0: 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
[  109.420993] ffe0: 00000000 00000000 00000000 00000000 00000013 00000000
[  109.421616] Code: e5928000 e006039c e0889006 e5995014 (e5953000)
[  109.422908] ---[ end trace ae90ba11d4cfb191 ]---

all i had was the traces (asked) from slub allocations.

Analysing the kdump showed me that memset() HAD NOT touched a single byte of allocated slab (szpage). for that to happen i thought that it was either an issue of concurrency (which did not happen in other architectures and TOO reproducible to be an async event) OR something related to where the slab was being allocated (and maybe kernel wasn't able to address it).

changing:

    handle = zs_malloc(zram->mem_pool, comp_len,
        __GFP_KSWAPD_RECLAIM |
        __GFP_NOWARN |
        __GFP_HIGHMEM |
        __GFP_MOVABLE);

for:

    handle = zs_malloc(zram->mem_pool, comp_len, GFP_ATOMIC);

"fixed" the issue:

"""
root@zramarmhf:~$ modprobe zram
[  805.243937] zram: Added device: zram0
root@zramarmhf:~$ echo 1073741824 > /sys/devices/virtual/block/zram0/disksize
[  807.743915] zram0: detected capacity change from 0 to 1073741824
root@zramarmhf:~$ mkfs.ext4 /dev/zram0
mke2fs 1.44.2 (14-May-2018)
Discarding device blocks: done
Creating filesystem with 262144 4k blocks and 65536 inodes
Filesystem UUID: ae667df2-a51f-42dd-b592-cbf796c83e26
Superblock backups stored on blocks:
  32768, 98304, 163840, 229376

Allocating group tables: done
Writing inode tables: done
Creating journal (8192 blocks): done
Writing superblocks and filesystem accounting information: done
"""

now i'm gonna check if that is because allocation was atomic (synchronous , no sleep, normal zone only) or because i'm not allocating from highmem (which might be the thing to blame for arm32, lets see).

will come back soon, hopefully with a final conclusion.


-----------------------

 * Physical address zone modifiers (see linux/mmzone.h - low four bits)

#define __GFP_DMA ((__force gfp_t)___GFP_DMA)
#define __GFP_HIGHMEM ((__force gfp_t)___GFP_HIGHMEM)
#define __GFP_DMA32 ((__force gfp_t)___GFP_DMA32)
#define __GFP_MOVABLE ((__force gfp_t)___GFP_MOVABLE)                      - can be moved or reclaimed by page migration
#define GFP_ZONEMASK  (__GFP_DMA|__GFP_HIGHMEM|__GFP_DMA32|__GFP_MOVABLE)

 * Page mobility and placement hints

#define __GFP_RECLAIMABLE ((__force gfp_t)___GFP_RECLAIMABLE)              - used by slab allocations
#define __GFP_WRITE ((__force gfp_t)___GFP_WRITE)                          - caller intends to dirty the pages
#define __GFP_HARDWALL   ((__force gfp_t)___GFP_HARDWALL)                  - enforces cpuset mem alloc policy
#define __GFP_THISNODE  ((__force gfp_t)___GFP_THISNODE)
#define __GFP_ACCOUNT ((__force gfp_t)___GFP_ACCOUNT)

 * Watermark modifiers -- controls access to emergency reserves

#define __GFP_ATOMIC ((__force gfp_t)___GFP_ATOMIC)           - high priority and cannot reclaim or sleep
#define __GFP_HIGH  ((__force gfp_t)___GFP_HIGH)              - high priority (usually top halves)
#define __GFP_MEMALLOC  ((__force gfp_t)___GFP_MEMALLOC)      - allows all memory (mm usually)
#define __GFP_NOMEMALLOC ((__force gfp_t)___GFP_NOMEMALLOC)   - forbids access to emergency reserves

 * Reclaim modifiers

#define __GFP_IO ((__force gfp_t)___GFP_IO)                               - can start physical I/O
#define __GFP_FS  ((__force gfp_t)___GFP_FS)                              - can call down to low-level fs
#define __GFP_DIRECT_RECLAIM  ((__force gfp_t)___GFP_DIRECT_RECLAIM)      - can enter direct reclaim
#define __GFP_KSWAPD_RECLAIM  ((__force gfp_t)___GFP_KSWAPD_RECLAIM)      - wake kswapd when low watermark is reached.
#define __GFP_RECLAIM ((__force gfp_t)(___GFP_DIRECT_RECLAIM|___GFP_KSWAPD_RECLAIM))
#define __GFP_RETRY_MAYFAIL ((__force gfp_t)___GFP_RETRY_MAYFAIL)         - wont trigger OOM killer, caller must handle failure
#define __GFP_NOFAIL  ((__force gfp_t)___GFP_NOFAIL)                      - VM must retry infinetely, caller wont handle failure
#define __GFP_NORETRY ((__force gfp_t)___GFP_NORETRY)                     - will try lightweight memory direct reclaim. will avoid OOM killer.

 * Action modifiers

#define __GFP_NOWARN  ((__force gfp_t)___GFP_NOWARN)    - suppresses allocation failure reports.
#define __GFP_COMP  ((__force gfp_t)___GFP_COMP)        - address compound page metadata.
#define __GFP_ZERO  ((__force gfp_t)___GFP_ZERO)        - returns a zeroed page on success.

 * Useful GFP flag combinations that are commonly used. It is recommended
 * that subsystems start with one of these combinations and then set/clear
 * __GFP_FOO flags as necessary.

#define GFP_ATOMIC (__GFP_HIGH|__GFP_ATOMIC|__GFP_KSWAPD_RECLAIM)   - users can not sleep and need the allocation to succeed.
#define GFP_KERNEL  (__GFP_RECLAIM | __GFP_IO | __GFP_FS)           - kernel-internal allocations (normal or lower zone, can dir reclaim)
#define GFP_KERNEL_ACCOUNT (GFP_KERNEL | __GFP_ACCOUNT)             - is the same as GFP_KERNEL (accounted diff)
#define GFP_NOWAIT  (__GFP_KSWAPD_RECLAIM)                          - kern allocations no stall direct reclaims, no start phy IO or FS cb
#define GFP_NOIO  (__GFP_RECLAIM)                                   - direct reclaim discard clean pages/slab. no direct use please. (all use)
#define GFP_NOFS  (__GFP_RECLAIM | __GFP_IO)                        - direct reclaim without fs direct calls. no direct use pls. (all use)
#define GFP_USER  (__GFP_RECLAIM | __GFP_IO | __GFP_FS | _...)      - userspace alloc, direct accessible by kern or hw. (graphics, etc)
#define GFP_DMA   __GFP_DMA                                         - caller requires lowest zone to be used. should be removed (audit needed)
#define GFP_DMA32 __GFP_DMA32                                       - similar to DMA except caller requires 32bit address
#define GFP_HIGHUSER  (GFP_USER | __GFP_HIGHMEM)                    - usersp alloc may be mapped to userspace, not dir accessible to kernel
                                                                      but cannot move once in use
#define GFP_HIGHUSER_MOVABLE  (GFP_HIGHUSER | __GFP_MOVABLE)        - userspace alloc that the kernel does not need direct access BUT can use
                                                                      kmap() when access is required. movable by page reclaim or migration.
-----------------------

OK

    handle = zs_malloc(zram->mem_pool, comp_len, __GFP_KSWAPD_RECLAIM | __GFP_MOVABLE);

root@zramarmhf:~$ modprobe zram
[   73.784784] zram: Added device: zram0
root@zramarmhf:~$ echo 1073741824 > /sys/devices/virtual/block/zram0/disksize
[   75.644400] zram0: detected capacity change from 0 to 1073741824
root@zramarmhf:~$ mkfs.ext4 /dev/zram0
mke2fs 1.44.2 (14-May-2018)
Discarding device blocks: done
Creating filesystem with 262144 4k blocks and 65536 inodes
Filesystem UUID: 274c030f-e234-4613-866f-1435efdd3f5e
Superblock backups stored on blocks:
  32768, 98304, 163840, 229376

Allocating group tables: done
Writing inode tables: done
Creating journal (8192 blocks): done
Writing superblocks and filesystem accounting information: done

-----------------------

NOT OK

    handle = zs_malloc(zram->mem_pool, comp_len, __GFP_KSWAPD_RECLAIM | __GFP_MOVABLE | __GFP_HIGHMEM);

root@zramarmhf:~$ modprobe zram
[  332.641112] zram: Added device: zram0
root@zramarmhf:~$ echo 1073741824 > /sys/devices/virtual/block/zram0/disksize
[  335.323057] zram0: detected capacity change from 0 to 1073741824
root@zramarmhf:~$
root@zramarmhf:~$
root@zramarmhf:~$ mkfs.ext4 /dev/zram0
mke2fs 1.44.2 (14-May-2018)
Discarding device blocks: done
Creating filesystem with 262144 4k blocks and 65536 inodes
Filesystem UUID: c6d3d836-3256-44fe-8c30-c184012f29e2
Superblock backups stored on blocks:
  32768, 98304, 163840, 229376

Allocating group tables: done
Writing inode tables: done
Creating journal (8192 blocks): done
Writing superblocks and filesystem accounting information: 
[  339.644555] Unable to handle kernel NULL pointer dereference at virtual address 00000000
[  339.645755] pgd = 7e18d621
[  339.646034] [00000000] *pgd=6c47d003, *pmd=00000000
[  339.647100] Internal error: Oops: 206 [#1] SMP ARM
[  339.647740] Modules linked in: zram zsmalloc evdev ip_tables x_tables autofs4

-----------------------

So, from past kdumps:

crash> kmem -S zspage

    CACHE    NAME                 OBJSIZE  ALLOCATED     TOTAL  SLABS  SSIZE
    eb9c6200 zspage                    28          1       128      1     4k
    CPU 0 KMEM_CACHE_CPU:
      ff7c0d30
    CPU 0 SLAB:
      (empty)
    CPU 0 PARTIAL:
      (empty)
    CPU 1 KMEM_CACHE_CPU:
      ff7d2d30
    CPU 1 SLAB:
      (empty)
    CPU 1 PARTIAL:
      (empty)
    CPU 2 KMEM_CACHE_CPU:
      ff7e4d30
    CPU 2 SLAB:
      (empty)
    CPU 2 PARTIAL:
      (empty)
    CPU 3 KMEM_CACHE_CPU:
      ff7f6d30
    CPU 3 SLAB:
      (empty)
    CPU 3 PARTIAL:
      (empty)
    KMEM_CACHE_NODE   NODE  SLABS  PARTIAL  PER-CPU
    eb93bec0             0      1        1        0
    NODE 0 PARTIAL:
      SLAB      MEMORY    NODE  TOTAL  ALLOCATED  FREE
      ee1daef8  e9d4e000     0    128          1   127
    NODE 0 FULL:
      (not tracked)

The slab is not coming from HIGHMEM (0xe9d4e000 == 3741 MB, addressable by kernel) so the change:

    handle = zs_malloc(zram->mem_pool, comp_len, __GFP_KSWAPD_RECLAIM | __GFP_MOVABLE);

Had only effect on alloc_zspage(), since it inherited the same flags used for zs_malloc:

    page = alloc_page(gfp);

and, slab allocations were already removing:

  return kmem_cache_alloc(pool->zspage_cachep,
      flags & ~(__GFP_HIGHMEM|__GFP_MOVABLE));

GFP_HIGHMEM flag.

confirming with:

    page = alloc_page(gfp & ~(__GFP_HIGHMEM|__GFP_MOVABLE));

I was able to make it work again. Meaning that zspage is broken when backed by HIGHMEM in arm32, definitely =).

TODOs:
 - check every place touching pages backing up a zspage, see if they're always kmapped()
 - check if kmap() is buggy for somereason, or there is enough mapping buffer for the request
 - enable HIGHMEM_DEBUG and see if there is any issue
 ... 


